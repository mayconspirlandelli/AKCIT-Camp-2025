## TechAdvisor ‚Äì Agente conversacional com LangChain + LangGraph

Um agente conversacional simples que d√° boas‚Äëvindas, coleta o nome do usu√°rio e entra em um ciclo de perguntas e respostas (Q&A) sobre tecnologia. Ele demonstra, de forma did√°tica, como:
- **carregar vari√°veis de ambiente** com `python-dotenv`;
- **construir prompts** com `PromptTemplate` (LangChain);
- **orquestrar um fluxo** com `LangGraph` utilizando um `StateGraph` com m√∫ltiplos n√≥s e arestas condicionais;
- **conectar um LLM Gemini (Google)** via `langchain-google-genai` usando a interface moderna (LCEL): `prompt | llm | StrOutputParser()`.

### Por que este projeto?
- Ideal para bootcamps e primeiros passos em agentes de IA.
- C√≥digo curto, claro e comentado para facilitar o aprendizado.

---

## Pr√©‚Äërequisitos
- Python 3.12+ (recomendado)
- Conta e chave de API do Google AI Studio (Gemini)
- macOS, Linux ou Windows com terminal

---

## Setup r√°pido (macOS/Linux)

1) Clonar o reposit√≥rio (ou abrir a pasta no seu ambiente):
```bash
cd /Users/seu-usuario/algum/lugar
git clone <seu-repo>.git
cd akcit/akcit-camp-2025/dia1
```

2) Criar e ativar o ambiente virtual:
```bash
python3 -m venv .venv
source .venv/bin/activate
```

3) Instalar as depend√™ncias espec√≠ficas do agente:
```bash
pip install -r techadvisor/requirements.txt
```

4) Configurar as vari√°veis de ambiente:
```bash
cp .env-sample .env
# edite o arquivo .env e coloque sua chave real
# GOOGLE_API_KEY=AIza....
```

> Dica: O arquivo `.env-sample` j√° existe na raiz do projeto. √â s√≥ copiar para `.env` e preencher a chave.

### Windows (PowerShell)
```powershell
py -m venv .venv
.\.venv\Scripts\Activate.ps1
pip install -r techadvisor\requirements.txt
copy .env-sample .env
# edite .env e informe GOOGLE_API_KEY
```

---

## Como rodar
Com o ambiente virtual ativo e `.env` configurado:
```bash
python techadvisor/techadvisor_agent.py
```

Exemplo de conversa (CLI):
```
ü§ñ TechAdvisor - Agente conversacional sobre tecnologia

Ol√°! Eu sou o TechAdvisor. Como posso te chamar?

Voc√™: Maria

üîé Agente: Prazer, Maria! Como posso ajudar em tecnologia hoje?

Voc√™: Quero aprender back-end com Python

üîé Agente: Recomendo come√ßar por FastAPI para criar APIs modernas...

Voc√™: tchau

üîé Agente: At√© logo, Maria! üëã

Conversa encerrada.
```

Para encerrar, digite `sair`/`exit`/`quit` (comando do app) ou diga `tchau` (condi√ß√£o do grafo).

---

## Como funciona (arquitetura did√°tica)

- `PromptTemplate` (LangChain): define o texto-base para Q&A com vari√°veis `{nome}` e `{pergunta}`.
- `ChatGoogleGenerativeAI` (langchain-google-genai): cria o LLM (Gemini) a ser usado.
- `LCEL` (LangChain Expression Language): conectamos `prompt | llm | StrOutputParser()` formando uma pipeline:
  - `prompt` injeta `{nome}` e `{pergunta}`
  - `llm` gera a resposta
  - `StrOutputParser()` garante que o resultado final seja string limpa
- `LangGraph`:
  - Estado: `{ "etapa", "mensagem_usuario", "nome", "resposta", "historico", ... }`.
  - N√≥ `boas_vindas`: envia sauda√ß√£o e pergunta o nome. Transi√ß√£o para `aguardar_nome`.
  - N√≥ `aguardar_nome`: espera input do usu√°rio e extrai o nome. Transi√ß√£o para `responder_perguntas`.
  - N√≥ `responder_perguntas`: responde usando LLM e mant√©m um loop (aresta para si mesmo via roteamento) at√© o usu√°rio dizer "tchau".
  - Condi√ß√£o de t√©rmino: se a mensagem cont√©m "tchau", transi√ß√£o para `END`.
  - Um n√≥ `roteador` decide, a cada turno, qual n√≥ executar baseado em `state['etapa']`.

### Diagrama do grafo (Mermaid)

```mermaid
flowchart LR
    entry([Entry Point]) --> ROT["N√≥: roteador"]
    ROT -->|etapa=boas_vindas| BV["N√≥: boas_vindas"]
    ROT -->|etapa=aguardar_nome| AN["N√≥: aguardar_nome"]
    ROT -->|etapa=responder_perguntas| RP["N√≥: responder_perguntas<br/>(prompt | llm | StrOutputParser)"]
    ROT -->|etapa=fim| fim([END])

    %% Turno √∫nico por invoca√ß√£o (cada n√≥ retorna ao chamador)
    BV --> fim
    AN --> fim
    RP --> fim

    %% Estado m√≠nimo
    subgraph Estado ["Estado"]
      E["state['etapa']"]
      MU["state['mensagem_usuario']"]
      N["state['nome']"]
      R["state['resposta']"]
    end
```

---

## Estrutura dos arquivos
- `techadvisor/techadvisor_agent.py`: c√≥digo do agente (altamente comentado).
- `techadvisor/requirements.txt`: depend√™ncias espec√≠ficas.
- `.env-sample`: modelo de vari√°veis de ambiente (na raiz do projeto).

---

## Personaliza√ß√µes comuns

- **Trocar o modelo**: no arquivo `techadvisor_agent.py`, altere `model="gemini-2.0-flash"` para outro modelo compat√≠vel na sua conta (ex.: `gemini-1.5-flash`).
- **Ajustar criatividade**: modifique `temperature=0.7`.
- **Mudar o prompt**: edite o `template_text` para orientar o agente a outro dom√≠nio (por exemplo, carreiras, cloud, dados, etc.).
- **Adicionar etapas**: inclua n√≥s adicionais (ex.: valida√ß√£o, desambigua√ß√£o) e conecte via `add_conditional_edges`.

---

## Interface web (Gradio)

Voc√™ pode iniciar um chat web simples com:

```bash
python techadvisor/agente_gui.py
```

Recursos:
- Chatbot com estado (cada mensagem roda um turno no LangGraph)
- Comando `/reset` para reiniciar a conversa
- Dica: tamb√©m √© poss√≠vel encerrar dizendo "tchau" (condi√ß√£o do grafo)


